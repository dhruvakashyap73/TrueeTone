{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNs6cVztIhnhSnMDhwx2XZf"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit librosa tensorflow torchaudio transformers scipy matplotlib scikit-learn librosa resampy\n",
        "!pip install pyngrok\n",
        "!pip install pydub\n",
        "!apt-get update\n",
        "!apt-get install -y ffmpeg\n",
        "!pip install pyngrok\n",
        "!pip install audio-recorder-streamlit\n",
        "!pip install reportlab\n",
        "!pip install fpdf2"
      ],
      "metadata": {
        "collapsed": true,
        "id": "BJXtHDSF7WkZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1efe9a1e-6df0-4509-dfe9-bc814efa34bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.44.1-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.14.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Collecting resampy\n",
            "  Downloading resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.1)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m885.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchaudio) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0->torchaudio)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0->torchaudio)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0->torchaudio)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0->torchaudio)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0->torchaudio)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0->torchaudio)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0->torchaudio)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0->torchaudio)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0->torchaudio)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0->torchaudio)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->torchaudio) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.34.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->torchaudio) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading streamlit-1.44.1-py3-none-any.whl (9.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, resampy, pydeck, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, streamlit\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pydeck-0.9.1 resampy-0.4.3 streamlit-1.44.1 watchdog-6.0.0\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.4-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.4-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.4\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:2 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [73.0 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,693 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,243 kB]\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,837 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,788 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,542 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,140 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,246 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\n",
            "Fetched 25.0 MB in 4s (6,346 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.4)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Collecting audio-recorder-streamlit\n",
            "  Downloading audio_recorder_streamlit-0.0.10-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: streamlit>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from audio-recorder-streamlit) (1.44.1)\n",
            "Collecting altair<5 (from audio-recorder-streamlit)\n",
            "  Downloading altair-4.2.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.11/dist-packages (from altair<5->audio-recorder-streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<5->audio-recorder-streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<5->audio-recorder-streamlit) (4.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from altair<5->audio-recorder-streamlit) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.18 in /usr/local/lib/python3.11/dist-packages (from altair<5->audio-recorder-streamlit) (2.2.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.11/dist-packages (from altair<5->audio-recorder-streamlit) (0.12.1)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.12.0->audio-recorder-streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.12.0->audio-recorder-streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.12.0->audio-recorder-streamlit) (8.1.8)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.12.0->audio-recorder-streamlit) (24.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.12.0->audio-recorder-streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.12.0->audio-recorder-streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.12.0->audio-recorder-streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.12.0->audio-recorder-streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.12.0->audio-recorder-streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.12.0->audio-recorder-streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.12.0->audio-recorder-streamlit) (4.13.1)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.12.0->audio-recorder-streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.12.0->audio-recorder-streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.12.0->audio-recorder-streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit>=1.12.0->audio-recorder-streamlit) (6.4.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.12.0->audio-recorder-streamlit) (4.0.12)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<5->audio-recorder-streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<5->audio-recorder-streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<5->audio-recorder-streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<5->audio-recorder-streamlit) (0.24.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.18->altair<5->audio-recorder-streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.18->altair<5->audio-recorder-streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.18->altair<5->audio-recorder-streamlit) (2025.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<5->audio-recorder-streamlit) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit>=1.12.0->audio-recorder-streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit>=1.12.0->audio-recorder-streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit>=1.12.0->audio-recorder-streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit>=1.12.0->audio-recorder-streamlit) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.12.0->audio-recorder-streamlit) (5.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=0.18->altair<5->audio-recorder-streamlit) (1.17.0)\n",
            "Downloading audio_recorder_streamlit-0.0.10-py3-none-any.whl (3.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading altair-4.2.2-py3-none-any.whl (813 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m813.6/813.6 kB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: altair, audio-recorder-streamlit\n",
            "  Attempting uninstall: altair\n",
            "    Found existing installation: altair 5.5.0\n",
            "    Uninstalling altair-5.5.0:\n",
            "      Successfully uninstalled altair-5.5.0\n",
            "Successfully installed altair-4.2.2 audio-recorder-streamlit-0.0.10\n",
            "Collecting reportlab\n",
            "  Downloading reportlab-4.3.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from reportlab) (11.1.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (from reportlab) (5.2.0)\n",
            "Downloading reportlab-4.3.1-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: reportlab\n",
            "Successfully installed reportlab-4.3.1\n",
            "Collecting fpdf2\n",
            "  Downloading fpdf2-2.8.2-py2.py3-none-any.whl.metadata (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from fpdf2) (0.7.1)\n",
            "Requirement already satisfied: Pillow!=9.2.*,>=6.2.2 in /usr/local/lib/python3.11/dist-packages (from fpdf2) (11.1.0)\n",
            "Requirement already satisfied: fonttools>=4.34.0 in /usr/local/lib/python3.11/dist-packages (from fpdf2) (4.57.0)\n",
            "Downloading fpdf2-2.8.2-py2.py3-none-any.whl (236 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.3/236.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fpdf2\n",
            "Successfully installed fpdf2-2.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WosRdwFwmamf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6623cb9a-c439-417a-de9f-ef780c07942a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile trueetone_app.py\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import torchaudio\n",
        "import io\n",
        "import os\n",
        "from PIL import Image\n",
        "from scipy.stats import skew, kurtosis, median_abs_deviation\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from io import BytesIO\n",
        "from pydub import AudioSegment\n",
        "from audio_recorder_streamlit import audio_recorder\n",
        "from fpdf import FPDF\n",
        "from datetime import datetime\n",
        "\n",
        "# Function to load image\n",
        "def load_image(image_path):\n",
        "    try:\n",
        "        with open(image_path, \"rb\") as file:\n",
        "            image_data = file.read()\n",
        "            if not image_data:\n",
        "                st.error(f\"Image file {image_path} is empty.\")\n",
        "                return None\n",
        "            return Image.open(io.BytesIO(image_data))\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error loading image {image_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Load Models (Ensure these paths are correct for your Google Drive)\n",
        "@st.cache_resource()\n",
        "def load_models():\n",
        "    try:\n",
        "        dnn_model = tf.keras.models.load_model(\"/content/drive/MyDrive/TrueeTone/Training/Saved Models/pre_trained_dense_model.h5\")\n",
        "        cnn_model = tf.keras.models.load_model(\"/content/drive/MyDrive/TrueeTone/Training/Saved Models/pre_trained_cnn_model.h5\")  # Change path if needed\n",
        "        bundle = torchaudio.pipelines.WAV2VEC2_ASR_BASE_960H\n",
        "        wav2vec_model = bundle.get_model()\n",
        "        return dnn_model, cnn_model, wav2vec_model, bundle\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error loading models: {e}\")\n",
        "        return None, None, None, None\n",
        "\n",
        "dnn_model, cnn_model, wav2vec_model, bundle = load_models()\n",
        "\n",
        "def convert_to_wav(audio_file):\n",
        "    \"\"\"Converts an uploaded audio file to WAV format.\"\"\"\n",
        "    try:\n",
        "        audio = AudioSegment.from_file(audio_file)\n",
        "        wav_io = BytesIO()\n",
        "        audio.export(wav_io, format=\"wav\")\n",
        "        wav_io.seek(0)\n",
        "        return wav_io\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error converting audio to WAV: {e}\")\n",
        "        return None\n",
        "\n",
        "# Prediction Functions\n",
        "def predict_dnn(audio_file_content, file_name):\n",
        "    try:\n",
        "        # Convert to WAV\n",
        "        wav_audio = convert_to_wav(io.BytesIO(audio_file_content))\n",
        "        if wav_audio is None:\n",
        "            return None\n",
        "\n",
        "        # Save converted WAV file to a temporary location\n",
        "        temp_file_path = f\"/tmp/{file_name}.wav\"  # Append .wav extension\n",
        "        with open(temp_file_path, \"wb\") as temp_file:\n",
        "            temp_file.write(wav_audio.read())\n",
        "\n",
        "        sound_signal, sample_rate = librosa.load(temp_file_path, res_type=\"kaiser_fast\")\n",
        "        mfcc_features = librosa.feature.mfcc(y=sound_signal, sr=sample_rate, n_mfcc=40)\n",
        "        mfccs_features_scaled = np.mean(mfcc_features.T, axis=0)\n",
        "        mfccs_features_scaled = mfccs_features_scaled.reshape(1, -1)\n",
        "        result_array = dnn_model.predict(mfccs_features_scaled)\n",
        "        result_classes = [\"AI\", \"Human\"]\n",
        "        result = np.argmax(result_array[0])\n",
        "        return result_classes[result]\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error in DNN prediction: {e}\")\n",
        "        return None\n",
        "\n",
        "def predict_cnn(audio_file_content, file_name):\n",
        "    try:\n",
        "        # Convert to WAV\n",
        "        wav_audio = convert_to_wav(io.BytesIO(audio_file_content))\n",
        "        if wav_audio is None:\n",
        "            return None\n",
        "\n",
        "        # Save converted WAV file to a temporary location\n",
        "        temp_file_path = f\"/tmp/{file_name}.wav\"  # Append .wav extension\n",
        "        with open(temp_file_path, \"wb\") as temp_file:\n",
        "            temp_file.write(wav_audio.read())\n",
        "\n",
        "        sound_signal, sample_rate = librosa.load(temp_file_path, res_type=\"kaiser_fast\")\n",
        "        mfcc_features = librosa.feature.mfcc(y=sound_signal, sr=sample_rate, n_mfcc=40)\n",
        "        mfccs_features_scaled = np.mean(mfcc_features.T, axis=0)\n",
        "\n",
        "        # Reshape the input to match the CNN model's expected shape (None, 40, 1, 1)\n",
        "        mfccs_features_scaled = mfccs_features_scaled.reshape(1, 40, 1, 1)  # Reshape to (1, 40, 1, 1)\n",
        "\n",
        "        result_array = cnn_model.predict(mfccs_features_scaled)\n",
        "        result_classes = [\"AI\", \"Human\"]\n",
        "        result = np.argmax(result_array[0])\n",
        "        return result_classes[result]\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error in CNN prediction: {e}\")\n",
        "        return None\n",
        "\n",
        "def extract_features(audio_file_content, file_name, bundle, model):\n",
        "    try:\n",
        "        # Convert to WAV\n",
        "        wav_audio = convert_to_wav(io.BytesIO(audio_file_content))\n",
        "        if wav_audio is None:\n",
        "            return None\n",
        "\n",
        "        # Save converted WAV file to a temporary location\n",
        "        temp_file_path = f\"/tmp/{file_name}.wav\"  # Append .wav extension\n",
        "        with open(temp_file_path, \"wb\") as temp_file:\n",
        "            temp_file.write(wav_audio.read())\n",
        "\n",
        "        waveform, sample_rate = torchaudio.load(temp_file_path)\n",
        "        if sample_rate != bundle.sample_rate:\n",
        "            waveform = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=bundle.sample_rate)(waveform)\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            features, _ = model.extract_features(waveform)\n",
        "\n",
        "        pooled_features = []\n",
        "        for f in features:\n",
        "            if f.dim() == 3:\n",
        "                f = f.permute(0, 2, 1)\n",
        "                pooled_f = F.adaptive_avg_pool1d(f[0].unsqueeze(0), 1).squeeze(0)\n",
        "                pooled_features.append(pooled_f)\n",
        "\n",
        "        final_features = torch.cat(pooled_features, dim=0).numpy()\n",
        "        final_features = (final_features - np.mean(final_features)) / (np.std(final_features) + 1e-10)\n",
        "        return final_features\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error extracting features: {e}\")\n",
        "        return None\n",
        "\n",
        "def additional_features(features):\n",
        "    if features is None:\n",
        "        return None, None\n",
        "    mad = median_abs_deviation(features)\n",
        "    features_clipped = np.clip(features, 1e-10, None)\n",
        "    entropy = -np.sum(features_clipped * np.log(features_clipped))\n",
        "    return mad, entropy\n",
        "\n",
        "def classify_audio(features):\n",
        "    if features is None:\n",
        "        return None, None\n",
        "    mean_value = np.mean(features)\n",
        "    variance_value = np.var(features)\n",
        "    skewness_value = skew(features)[0]\n",
        "    kurtosis_value = kurtosis(features)[0]\n",
        "    _, entropy = additional_features(features)\n",
        "    if entropy is None:\n",
        "        return None, None\n",
        "    if entropy > 200:\n",
        "        return \"Human\", entropy\n",
        "    else:\n",
        "        return \"AI\", entropy\n",
        "\n",
        "def predict_wav2vec(audio_file_content, file_name, bundle, model):\n",
        "    try:\n",
        "        features = extract_features(audio_file_content, file_name, bundle, model)\n",
        "        if features is not None:\n",
        "            prediction, entropy = classify_audio(features)\n",
        "            return prediction, entropy\n",
        "        else:\n",
        "            return None, None\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error in Wav2Vec prediction: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# Spectrogram Function\n",
        "def plot_mel_spectrogram(audio_file_content, file_name):\n",
        "    try:\n",
        "        # Convert to WAV for plotting spectrogram.\n",
        "        wav_audio = convert_to_wav(io.BytesIO(audio_file_content))\n",
        "        if wav_audio is None:\n",
        "            return\n",
        "\n",
        "        # Save converted WAV file to a temporary location\n",
        "        temp_file_path = f\"/tmp/{file_name}.wav\"\n",
        "        with open(temp_file_path, \"wb\") as temp_file:\n",
        "            temp_file.write(wav_audio.read())\n",
        "\n",
        "        y, sr = librosa.load(temp_file_path)\n",
        "        mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr)\n",
        "        mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        img = librosa.display.specshow(mel_spectrogram_db, x_axis='time', y_axis='mel', sr=sr, fmax=8000, ax=ax)\n",
        "        fig.colorbar(img, ax=ax, format='%+2.0f dB')\n",
        "        ax.set(title='Mel-frequency spectrogram')\n",
        "        st.pyplot(fig)\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error plotting spectrogram: {e}\")\n",
        "\n",
        "class PDF(FPDF):\n",
        "    def header(self):\n",
        "        self.set_fill_color(255, 253, 208)\n",
        "        self.rect(0, 0, 210, 297, style='F')\n",
        "        self.rect(5, 5, 200, 287)\n",
        "\n",
        "# Function to generate PDF report\n",
        "def generate_report(file_name, duration, file_type, dnn_prediction, cnn_prediction, wav2vec_prediction, entropy, final_description):\n",
        "    pdf = PDF()\n",
        "    pdf.add_page()\n",
        "\n",
        "    # Add Logo\n",
        "    logo_width = 20\n",
        "    logo_x = (210 - logo_width) / 2\n",
        "    pdf.image(\"/content/drive/MyDrive/TrueeTone/Training/Images/logo.png\", x=logo_x, y=10, w=logo_width)\n",
        "    pdf.ln(25)\n",
        "\n",
        "    # Set Title\n",
        "    pdf.set_font(\"Helvetica\", \"BI\", 18)\n",
        "    pdf.cell(200, 10, txt=\"TrueeTone: Audio Authenticity Detection\", ln=True, align='C')\n",
        "    pdf.set_font(\"Arial\",'I',14)\n",
        "    pdf.cell(200, 10, txt=\"Audio Analysis Report\", ln=True, align='C')\n",
        "    pdf.ln(5)\n",
        "\n",
        "    pdf.set_font(\"Arial\", 'B', 8)\n",
        "    current_date = datetime.now().strftime(\"%Y-%m-%d\")  # Format: YYYY-MM-DD\n",
        "    current_time = datetime.now().strftime(\"%H:%M:%S\")  # Format: HH:MM:SS\n",
        "    pdf.cell(200, 10, txt=f\"Report Generated On: Date: {current_date}, Time: {current_time}\", ln=True, align='C')\n",
        "    pdf.ln(5)\n",
        "\n",
        "    # Audio File Details\n",
        "    pdf.line(10, pdf.get_y(), 200, pdf.get_y())\n",
        "    pdf.set_font(\"Arial\", 'B', 14)\n",
        "    pdf.cell(200, 10, txt=\"Details on Audio File\", ln=True, align='C')\n",
        "    pdf.line(10, pdf.get_y(), 200, pdf.get_y())\n",
        "    pdf.set_font(\"Arial\", size=12)\n",
        "    pdf.cell(200, 10, txt=f\"File Name: {file_name}\", ln=True)\n",
        "    pdf.cell(200, 10, txt=f\"Duration: {duration:.2f} seconds\", ln=True)\n",
        "    pdf.cell(200, 10, txt=f\"File Type: {file_type.upper()}\", ln=True)\n",
        "    pdf.ln(5)\n",
        "    pdf.line(10, pdf.get_y(), 200, pdf.get_y())\n",
        "\n",
        "    # Predictions\n",
        "    pdf.set_font(\"Arial\", 'B', 14)\n",
        "    pdf.cell(200, 10, txt=\"Predictions\", ln=True, align='C')\n",
        "    pdf.line(10, pdf.get_y(), 200, pdf.get_y())\n",
        "    pdf.set_font(\"Arial\", size=12)\n",
        "    pdf.cell(200, 10, txt=f\"DNN Prediction: {dnn_prediction}\", ln=True)\n",
        "    pdf.cell(200, 10, txt=f\"CNN Prediction: {wav2vec_prediction}\", ln=True)\n",
        "    pdf.cell(200, 10, txt=f\"Wav2Vec Prediction: {wav2vec_prediction} (Entropy: {entropy:.2f})\", ln=True)\n",
        "    pdf.ln(5)\n",
        "    pdf.line(10, pdf.get_y(), 200, pdf.get_y())\n",
        "\n",
        "    # Plots Section\n",
        "    pdf.set_font(\"Arial\", 'B', 14)\n",
        "    pdf.cell(200, 10, txt=\"Audio Data Analysis\", ln=True, align='C')\n",
        "    pdf.line(10, pdf.get_y(), 200, pdf.get_y())\n",
        "\n",
        "    # Ensure plots exist before adding\n",
        "    plot_paths = [\n",
        "        (\"/tmp/audio_waveform.png\", \"Waveform\"),\n",
        "        (\"/tmp/mel_spectrogram.png\", \"Mel Spectrogram\"),\n",
        "        (\"/tmp/mfcc.png\", \"MFCC Features\")\n",
        "    ]\n",
        "    pdf.ln(5)\n",
        "    for path, title in plot_paths:\n",
        "      if os.path.exists(path):\n",
        "        image_width = 100\n",
        "        x_centered = (210 - image_width) / 2\n",
        "        pdf.image(path, x=x_centered, w=image_width)\n",
        "        pdf.set_font(\"Arial\", 'I', 12)\n",
        "        pdf.cell(200, 10, txt=title, ln=True, align='C')\n",
        "        pdf.ln(5)\n",
        "    pdf.line(10, pdf.get_y(), 200, pdf.get_y())\n",
        "\n",
        "    # Final Description\n",
        "    pdf.set_font(\"Arial\", 'B', 14)\n",
        "    pdf.cell(200, 10, txt=\"Final Description\", ln=True, align='C')\n",
        "    pdf.line(10, pdf.get_y(), 200, pdf.get_y())\n",
        "    pdf.set_font(\"Arial\", size=12)\n",
        "    pdf.multi_cell(0, 10, txt=final_description)\n",
        "    pdf.ln(10)\n",
        "\n",
        "    # Importance of Audio Authenticity Detection (Light Gray Heading)\n",
        "    pdf.line(10, pdf.get_y(), 200, pdf.get_y())\n",
        "    pdf.set_text_color(0, 0, 169)  # Dark Blue Color\n",
        "    pdf.set_font(\"Arial\", 'B', 14)\n",
        "    pdf.cell(200, 10, txt=\"Importance of Audio Authenticity Detection\", ln=True, align='C')\n",
        "    pdf.line(10, pdf.get_y(), 200, pdf.get_y())  # Separator line\n",
        "    pdf.set_text_color(0, 0, 139)  # Dark Blue Color\n",
        "    pdf.set_font(\"Arial\", \"\", 12)\n",
        "    importance_text = \"\"\"With the rise of AI-generated content, ensuring the authenticity of audio recordings has become critical. Misinformation, deepfake technology, and synthetic speech pose serious threats to security, journalism, and personal identity. Detecting AI-generated audio helps prevent fraud, protect intellectual property, and maintain trust in digital communications. TrueeTone's advanced models empower users to verify the authenticity of voice recordings, making digital interactions safer and more transparent.\"\"\"\n",
        "    pdf.multi_cell(0, 10, txt=importance_text)\n",
        "    pdf.ln(10)\n",
        "\n",
        "    # Save the PDF\n",
        "    pdf_output = f\"/tmp/{file_name}_report.pdf\"\n",
        "    pdf.output(pdf_output)\n",
        "    return pdf_output\n",
        "\n",
        "\n",
        "# Home Page\n",
        "def home_page():\n",
        "\n",
        "    st.title(\"🔊 TrueeTone: Audio Authenticity Detection\")\n",
        "\n",
        "    st.markdown(\"\"\"\n",
        "    ## Introduction\n",
        "    In the age of artificial intelligence, distinguishing between human and AI-generated voices has become a significant challenge.\n",
        "    With the rise of deepfake technology and synthetic speech, there is an increasing need for reliable detection mechanisms.\n",
        "    **TrueeTone: Audio Authenticity Detection System** is an advanced AI-ML-powered solution designed to differentiate between real human voices and AI-generated audio with high accuracy.\n",
        "    \"\"\")\n",
        "\n",
        "    # Add Audio Authenticity Photo\n",
        "    st.image(\"/content/drive/MyDrive/TrueeTone/Training/Images/bg.jpeg\")\n",
        "\n",
        "    st.markdown(\"\"\"\n",
        "    ## Overview\n",
        "    TrueeTone is built using an ensemble classification approach, leveraging multiple machine learning models to ensure robust and precise results.\n",
        "    By analyzing unique audio features, the system provides a comprehensive authenticity evaluation for any given audio clip.\n",
        "    The application is designed to be user-friendly, allowing individuals, researchers, and organizations to verify the legitimacy of voice recordings effortlessly.\n",
        "    \"\"\")\n",
        "\n",
        "    st.image(\"/content/drive/MyDrive/TrueeTone/Training/Images/logo.png\")\n",
        "\n",
        "    st.markdown(\"\"\"\n",
        "    ## Core Technology\n",
        "    The system employs the following models to detect AI-generated voices:\n",
        "    1. **Dense Neural Network (DNN) with MFCC Features** – Extracts Mel-Frequency Cepstral Coefficients (MFCC) features and uses a dense neural network to classify the audio as real or fake.\n",
        "    2. **Convolutional Neural Network (CNN) with MFCC Features** – Enhances feature extraction capabilities using CNN layers for improved accuracy.\n",
        "    3. **Pretrained Wav2Vec-960h Model** – A state-of-the-art model that analyzes entropy values to make precise predictions about audio authenticity.\n",
        "    \"\"\")\n",
        "\n",
        "    # Add Model Accuracy Graphs\n",
        "    st.image(\"/content/drive/MyDrive/TrueeTone/Training/Images/ModelAccCNN.png\", caption=\"CNN Model Accuracy\")\n",
        "    st.image(\"/content/drive/MyDrive/TrueeTone/Training/Images/ModelAccDNN.png\", caption=\"Dense Model Accuracy\")\n",
        "\n",
        "    st.markdown(\"\"\"\n",
        "    ## How It Works\n",
        "    Users can interact with TrueeTone through a Streamlit-based web application, which provides:\n",
        "    - **Audio Upload & Recording**: Users can either upload an audio file or record their voice directly in the app.\n",
        "    - **Mel Spectrogram Visualization**: A visual representation of the audio signal to understand its frequency distribution.\n",
        "    - **Multi-Model Predictions**: Displays results from all three models, highlighting the most confident prediction (typically Wav2Vec-based analysis).\n",
        "    \"\"\")\n",
        "\n",
        "    st.markdown(\"\"\"\n",
        "    ## Outcomes\n",
        "    TrueeTone serves as a crucial tool in combating the spread of AI-generated misinformation in audio content.\n",
        "    By combining deep learning with advanced signal processing, the system offers a reliable and efficient way to authenticate voice recordings.\n",
        "    As synthetic voice technology evolves, TrueeTone will continue to adapt, ensuring transparency and trust in digital communications.\n",
        "    \"\"\")\n",
        "\n",
        "# Prediction Page\n",
        "def prediction_page():\n",
        "    st.title(\"🎙️ Audio Authenticity Prediction\")\n",
        "\n",
        "    # Audio Input Options\n",
        "    option = st.radio(\"Choose an option:\", (\"Upload Audio File\", \"Record Audio\"))\n",
        "\n",
        "    if option == \"Upload Audio File\":\n",
        "        audio_file = st.file_uploader(\"Upload Audio File\", type=[\"wav\", \"mp3\", \"ogg\"])\n",
        "        if audio_file is not None:\n",
        "            st.audio(audio_file, format=\"audio/wav\")\n",
        "            process_audio(audio_file.read(), audio_file.name)\n",
        "\n",
        "    elif option == \"Record Audio\":\n",
        "        st.write(\"Click the button below to start recording:\")\n",
        "        # Center the microphone\n",
        "        col1, col2, col3 = st.columns([1, 2, 1])\n",
        "        with col2:\n",
        "            audio_bytes = audio_recorder()\n",
        "        if audio_bytes:\n",
        "            st.audio(audio_bytes, format=\"audio/wav\")\n",
        "            process_audio(audio_bytes, \"recorded_audio.wav\")\n",
        "\n",
        "def process_audio(audio_file_content, file_name):\n",
        "    \"\"\"Processes the audio file (uploaded or recorded) and displays predictions.\"\"\"\n",
        "    # Convert to WAV for audio display and processing\n",
        "    wav_audio = convert_to_wav(io.BytesIO(audio_file_content))\n",
        "    if wav_audio is None:\n",
        "        return\n",
        "\n",
        "    # Display Mel Spectrogram\n",
        "    st.subheader(\"Mel Spectrogram\")\n",
        "    plot_mel_spectrogram(audio_file_content, file_name)\n",
        "\n",
        "    # Predictions\n",
        "    st.subheader(\"Predictions\")\n",
        "\n",
        "    dnn_prediction = predict_dnn(audio_file_content, file_name)\n",
        "\n",
        "    cnn_prediction = predict_cnn(audio_file_content, file_name)\n",
        "\n",
        "    wav2vec_prediction, entropy = predict_wav2vec(audio_file_content, file_name, bundle, wav2vec_model)\n",
        "\n",
        "    if dnn_prediction:\n",
        "        st.write(f\"DNN Prediction: {dnn_prediction}\")\n",
        "\n",
        "    if cnn_prediction:\n",
        "        st.write(f\"CNN Prediction: {wav2vec_prediction}\")\n",
        "\n",
        "    if wav2vec_prediction:\n",
        "        st.write(f\"Wav2Vec Prediction: {wav2vec_prediction} (Entropy: {entropy:.2f})\")\n",
        "\n",
        "    # Best Prediction (Based on Wav2Vec)\n",
        "    st.subheader(\"Best Prediction\")\n",
        "    if wav2vec_prediction == \"AI\":\n",
        "        st.warning(\"This audio is likely AI-generated.\")\n",
        "        final_description = \"The audio is likely AI-generated based on the entropy value and model predictions.\"\n",
        "    elif wav2vec_prediction == \"Human\":\n",
        "        st.success(\"This audio is likely Human-generated.\")\n",
        "        final_description = \"The audio is likely Human-generated based on the entropy value and model predictions.\"\n",
        "    else:\n",
        "        st.write(\"Unable to determine audio authenticity.\")\n",
        "        final_description = \"Unable to determine audio authenticity based on the provided data.\"\n",
        "\n",
        "    # Generate Report\n",
        "    #st.subheader(\"Generate Report\")\n",
        "    if st.button(\"Generate Report\"):\n",
        "        # Save plots to temporary files\n",
        "        plt.figure()\n",
        "        y, sr = librosa.load(f\"/tmp/{file_name}.wav\")\n",
        "        plt.plot(y)\n",
        "        plt.title(\"Audio Waveform\")\n",
        "        plt.xlabel(\"Time\")\n",
        "        plt.ylabel(\"Amplitude\")\n",
        "        plt.savefig(\"/tmp/audio_waveform.png\")\n",
        "        plt.close()\n",
        "\n",
        "        # Save Mel Spectrogram\n",
        "        #plot_mel_spectrogram(audio_file_content, file_name)\n",
        "        plt.savefig(\"/tmp/mel_spectrogram.png\")\n",
        "        plt.close()\n",
        "\n",
        "        # Save MFCC Plot\n",
        "        y, sr = librosa.load(f\"/tmp/{file_name}.wav\")\n",
        "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
        "        plt.figure(figsize=(10, 4))\n",
        "        librosa.display.specshow(mfccs, x_axis='time')\n",
        "        plt.colorbar()\n",
        "        plt.title('MFCC')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"/tmp/mfcc.png\")\n",
        "        plt.close()\n",
        "\n",
        "        # Get audio duration\n",
        "        duration = librosa.get_duration(y=y, sr=sr)\n",
        "\n",
        "        # Get file type\n",
        "        file_type = file_name.split(\".\")[-1]\n",
        "\n",
        "        # Generate PDF report\n",
        "        pdf_path = generate_report(\n",
        "            file_name=file_name,\n",
        "            duration=duration,\n",
        "            file_type=file_type,\n",
        "            dnn_prediction=dnn_prediction,\n",
        "            cnn_prediction=cnn_prediction,\n",
        "            wav2vec_prediction=wav2vec_prediction,\n",
        "            entropy=entropy,\n",
        "            final_description=final_description\n",
        "        )\n",
        "\n",
        "        # Provide download link for the report\n",
        "        with open(pdf_path, \"rb\") as pdf_file:\n",
        "            pdf_bytes = pdf_file.read()\n",
        "        st.download_button(\n",
        "            label=\"Download Report\",\n",
        "            data=pdf_bytes,\n",
        "            file_name=f\"{file_name}_report.pdf\",\n",
        "            mime=\"application/pdf\"\n",
        "        )\n",
        "\n",
        "# Main App\n",
        "def main():\n",
        "    st.sidebar.title(\"Dashboard\")\n",
        "    page = st.sidebar.selectbox(\"Select Page\", [\"Home\", \"Prediction\"])\n",
        "\n",
        "    if page == \"Home\":\n",
        "        home_page()\n",
        "    elif page == \"Prediction\":\n",
        "        prediction_page()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "x7401euLmgV6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07c70161-96f5-4b3f-faeb-f97c656e5b23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing trueetone_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run trueetone_app.py &>/dev/null&"
      ],
      "metadata": {
        "id": "jCqK4qIAxfhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Replace 'YOUR_NGROK_AUTHTOKEN' with your actual ngrok authtoken\n",
        "ngrok.set_auth_token('2tMZiGmKKB3qVX6bI2qWyCybtWs_ZURjBYw4NBuMC2iGMc6r')\n",
        "\n",
        "# Terminate open tunnels if any\n",
        "ngrok.kill()\n",
        "\n",
        "# Start a new ngrok tunnel\n",
        "public_url = ngrok.connect(addr='8501', proto='http')\n",
        "print(\"Public URL:\", public_url)"
      ],
      "metadata": {
        "id": "FUi6POw6mq7B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c3eee41-140d-4610-ef67-efb53587ee48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.4)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Public URL: NgrokTunnel: \"https://f12c-34-72-154-183.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    }
  ]
}
